# -*- coding: utf-8 -*-
"""Aula 13 - 19/05 -- Joao Sassi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TQez22_OzWWPqEUOn2AgZ2tXd9OkDhS_

# Pipeline de Classificação de Texto

### E00 - Base de dados
"""

import pandas as pd

data = {
  'texto': [
    "Este é um otimo filme!",
    "O produto é muito ruim.",
    "Adorei o atendimento ao cliente.",
    "A entrega atrasou e o produto veio com defeito.",
    "Recomendo este livro a todos!",
    "Não gostei da experiência.",
    "O serviço foi excelente.",
    "Péssima qualidade, não comprem!",
    "Amei o presente, muito obrigado!",
    "Que decepcao, perdi meu dinheiro."
  ],
  'categoria': [
    "positivo",
    "negativo",
    "positivo",
    "negativo",
    "positivo",
    "negativo",
    "positivo",
    "negativo",
    "positivo",
    "negativo"
  ]
}

df = pd.DataFrame(data)

df.to_csv('dados_rotulados.csv', index=False, encoding='utf-8')

print("Base de dados criada e salva em 'dados_rotulados.csv'")

"""### E01 - Preparação dos dados"""

import nltk
import spacy
import sklearn
import pandas as pd
import matplotlib.pyplot as plt
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
from sklearn.model_selection import train_test_split

#nltk.download('stopwords')
#nltk.download('punkt_tab')

data = pd.read_csv('dados_rotulados.csv', encoding='utf-8')

print("Informacoes do conjunto de dados:")
print(data.info())

print("\nPrimeiras 5 linhas do conjunto de dados:")
print (data.head())

# Categorias
plt.figure(figsize=(10, 5))
data['categoria'].value_counts().plot(kind='bar')
plt.title('Distribuicao das Categorias')
plt.xlabel('Categoria')
plt.ylabel('Contagem' )
plt. show()

# Tamanho
tamanhos_textos = data['texto' ].apply(len)
plt.figure(figsize=(10, 5))
plt.hist (tamanhos_textos, bins=50)
plt.title('Tamanho dos Textos')
plt.xlabel('Tamanho do Texto' )
plt.ylabel('Frequencia')
plt.show()

def preprocessar_texto(texto):
  texto = texto. translate(str.maketrans('', '', string.punctuation))
  texto = ''.join([c for c in texto if not c.isdigit()])

  tokens = word_tokenize(texto.lower())

  stop_words = set(stopwords.words('portuguese'))
  tokens = [palavra for palavra in tokens if palavra not in stop_words]

  stemmer = SnowballStemmer('portuguese')
  tokens = [stemmer.stem(palavra) for palavra in tokens]
  return ' '.join(tokens)

data['texto_processado' ] = data['texto' ].apply(preprocessar_texto)

X_train, X_test, y_train, y_test = train_test_split(
  data['texto_processado' ], data['categoria' ], test_size=0.2, random_state=42)

print("\nTamanho do conjunto de treinamento:", len(X_train))
print("Tamanho do conjunto de teste:", len(X_test) )

"""### E02 - Extração de características"""

from sklearn. feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer. transform(X_test)

print("\nNumero de caracteristicas extraidas:", X_train_tfidf.shape[1])

modelo = MultinomialNB()
modelo.fit(X_train_tfidf, y_train)

y_pred = modelo.predict(X_test_tfidf)
acuracia = accuracy_score(y_test, y_pred)
print("\nAcuracia do modelo:", acuracia)
print("\nRelatorio de Classificacao:\n", classification_report(y_test, y_pred) )

def classificar_texto(texto, vectorizer, modelo):
  texto_processado = preprocessar_texto(texto)
  texto_tfidf = vectorizer. transform([texto_processado])

  categoria_prevista = modelo.predict(texto_tfidf)[0]
  probabilidades = modelo.predict_proba(texto_tfidf)[0]

  categorias = modelo.classes_
  probabilidades_por_categoria = dict(zip(categorias, probabilidades))
  return categoria_prevista, probabilidades_por_categoria

novo_texto = "Este filme e incrivel, recomendo a todos!"
categoria, probabilidades = classificar_texto(novo_texto, vectorizer, modelo)
print("Novo texto:", novo_texto)
print("Categoria prevista:", categoria)
print("Probabilidades por categoria:", probabilidades)

"""### E03 - Treinamento de um modelo"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

naive_bayes_model = MultinomialNB()
svm_model = SVC(random_state=42, probability=True)

naive_bayes_model.fit(X_train_tfidf, y_train)
svm_model.fit(X_train_tfidf, y_train)

param_grid_nb = {}

param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf' ]}
grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=2)

grid_search_svm.fit(X_train_tfidf, y_train)

print("Melhores hiperparametros para SVM:", grid_search_svm.best_params_)

best_svm_model = grid_search_svm.best_estimator_

print("\nResultados da avaliação:")

# Naive Bayes
y_pred_nb = naive_bayes_model.predict(X_test_tfidf)
acuracia_nb = accuracy_score(y_test, y_pred_nb)
print("\nNaive Bayes Multinomial:")
print("Acurácia:", acuracia_nb)
print("Relatório de Classificacão:\n", classification_report(y_test, y_pred_nb))

# SVM
y_pred_svm = best_svm_model.predict(X_test_tfidf)
acuracia_svm = accuracy_score(y_test, y_pred_svm)
print("\nSVM:")
print("Acurácia:", acuracia_svm)
print("Relatório de Classificacão:\n", classification_report(y_test, y_pred_svm) )


def classificar_texto(texto, vectorizer, modelo):
  texto_processado = preprocessar_texto(texto)
  texto_tfidf = vectorizer. transform([texto_processado])

  categoria_prevista = modelo.predict(texto_tfidf)[0]
  probabilidades = modelo.predict_proba(texto_tfidf)[0]

  categorias = modelo.classes_
  probabilidades_por_categoria = dict(zip(categorias, probabilidades))
  return categoria_prevista, probabilidades_por_categoria

novo_texto = "Este filme e incrivel, recomendo a todos!"
categoria_nb, probabilidades_nb = classificar_texto(novo_texto, vectorizer, naive_bayes_model)
categoria_svm, probabilidades_svm = classificar_texto(novo_texto, vectorizer, best_svm_model)

print("\nNovo texto:", novo_texto)
print("\nResultados da classificação:")
print("\nNaive Bayes Multinomial:")
print("Categoria prevista:", categoria_nb)
print("Probabilidades por categoria:", probabilidades_nb)
print("\nSVM:")
print("Categoria prevista:", categoria_svm)
print("Probabilidades por categoria:", probabilidades_svm)

"""### E04 - Avaliação do modelo"""

print("\nEtapa 4: Avaliação do Modelo")
print("\nResultados da Avaliação:")

# Naive Bayes
y_pred_nb = naive_bayes_model.predict(X_test_tfidf)
acuracia_nb = accuracy_score(y_test, y_pred_nb)
print("\nNaive Bayes Multinomial:")
print ("Acurácia:", acuracia_nb)
print("Relatorio de Classificacao:\n", classification_report(y_test, y_pred_nb, zero_division=0))

# SVM
y_pred_svm = best_svm_model.predict(X_test_tfidf)
acuracia_svm = accuracy_score(y_test, y_pred_svm)
print("\nSVM:")
print("Acurácia:", acuracia_svm)
print ("Relatorio de Classificacao:\n", classification_report(y_test, y_pred_svm, zero_division=0))

print("\nComparação de Modelos:")
print(f"- Acurácia Naive Bayes: {acuracia_nb: .4f}")
print (f"- Acurácia SVM: {acuracia_svm: .4f}")

modelos = ['Naive Bayes', 'SVM' ]
acuracias = [acuracia_nb, acuracia_svm]

plt.figure(figsize=(8, 6))
plt.bar(modelos, acuracias, color=['blue', 'red' ])
plt.xlabel('Modelo')
plt.ylabel('Acuracia')
plt.title('Comparacao de Acuracia dos Modelos')
plt.ylim(0, 1)
plt.show()

"""### E05 - Classificação de um novo texto"""

print("\nEtapa 5: Classificacao de um Novo Texto")

def classificar_novo_texto(texto, vectorizer, modelo):
  texto_processado = preprocessar_texto(texto)
  texto_tfidf = vectorizer. transform([texto_processado])

  categoria_prevista = modelo.predict(texto_tfidf)[0]
  try:
    probabilidades = modelo.predict_proba(texto_tfidf)[0]
    categorias = modelo.classes_
    probabilidades_por_categoria = dict(zip(categorias, probabilidades))
    return categoria_prevista, probabilidades_por_categoria
  except AttributeError:
    return categoria_prevista, {}

novo_texto = "Este filme é incrivel, recomendo a todos!"

print("\nNovo Texto:", novo_texto)
print("\nResultados da Classificação:")

# Naive Bayes
categoria_nb, probabilidades_nb = classificar_novo_texto(novo_texto, vectorizer, naive_bayes_model)
print("\nNaive Bayes:")
print(" Categoria Prevista:", categoria_nb)
if probabilidades_nb:
  print("Probabilidades:", probabilidades_nb)

# CSVM
categoria_svm, probabilidades_svm = classificar_novo_texto(novo_texto, vectorizer, best_svm_model)
print("\nSVM:")
print(" Categoria Prevista:", categoria_svm)
if probabilidades_svm:
  print("Probabilidades:", probabilidades_svm)