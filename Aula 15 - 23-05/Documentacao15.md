# Documentação - Aula 15

## Objetivo
Nessa aula implementamos modelos de redes neurais recorrentes (RNN e LSTM). Usamos para previsão de próxima palavra e análise de sentimentos.

## Técnicas
- Tokenização com o pacote `Tokenizer`
- Padding de sequências com o pacote `pad_sequences`
- Implementamos o modelo RNN simples
- Implementamos o modelo LSTM
- Embedding layer para poder ter representação vetorial das palavras
- Visualização com matplotlib/seaborn

## Observações
- Tivemos uma implementação completa de dois modelos diferentes
- Utilizamos um Dataset pequeno criado manualmente
- Apesar dos modelos serem pequenos, foram bem didáticos